# -*- coding: utf-8 -*-
import scrapy
from scrapy import Request
from tatoeba_sentence.items import SentenceItem
from manageset.models import Kanji, Sentence, Words, SentenceOwner


class TatoebaSentenceSpider(scrapy.Spider):
    name = "sentences"
    rotate_user_agent = True
    allowed_domains = ["tatoeba.org", "jisho.org"]
    # all_words = Words.objects.all()
    # start_urls = []
    
    def start_requests(self):
	count = 0
        all_words = Words.objects.filter(sentence_scrape=False).order_by('combined_frequency') 
        for word in all_words:
	    print word.id
	    word.sentence_scraper = True
	    word.save()
	    count += 1
	    print count
	    if word.real_word == "none":
		vocab_word = word.hiragana
	    else:
		vocab_word = word.real_word
	    url = 'http://jisho.org/search/' + vocab_word + '%23sentence'
	    the_request = scrapy.Request(url, self.parse, meta={'word': vocab_word, 'word_id': word.id})
            yield the_request


    def parse(self, response):
        print response.meta['word']
        for sentence in response.css('.inline_copyright'):
           # print response.meta['word']
            #print response.meta['word']
            tatoeba_url = sentence.css('a::attr(href)').extract()
            jisho_url = response.url
            request = Request(tatoeba_url[0], callback=self.parse_tatoeba)
            request.meta['word'] = response.meta['word']
	    request.meta['word_id'] = response.meta['word_id']
            yield request

        next_page = response.css(".more::attr('href')")
        if next_page:
            url = response.urljoin(next_page[0].extract())
            request = Request(url, self.parse)

            request.meta['word'] = response.meta['word']
	    request.meta['word_id'] = response.meta['word_id']

            yield request

    def parse_tatoeba(self, response):
        for sentence_set in response.css('.sentences_set'):

            item = SentenceItem()

            japanese_sentence = sentence_set.css('.mainSentence .text::text').extract()[0]
            english_sentence = sentence_set.css('.correctnessZero:lang(en)::text').extract()
            sentence_owner = response.css('.adopt-item::text').extract()
            no_comment = response.css('.module em')
	    try:
                item['sentence_owner'] = sentence_owner[0]
	        print "sentence owner is: ", sentence_owner[0]
	    except:
	        item['sentence_owner'] = ' '		    
            if english_sentence: 
                item['english_sentence'] = english_sentence[0]
            else:
                item['english_sentence'] = ' '
            if no_comment:
                item['comment_exists'] = False
            else:
                item['comment_exists'] = True

            item['japanese_sentence'] = japanese_sentence
            item['source_url'] = response.url
            item['source_id'] = response.url.rsplit('/',1)[1]
            item['words'] = response.meta['word']
	    item['word_id'] = response.meta['word_id']
            yield item
